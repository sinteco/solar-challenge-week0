{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02058d2e",
   "metadata": {},
   "source": [
    "# Benin EDA\n",
    "\n",
    "This notebook contains an end-to-end scaffold for profiling, cleaning, and exploratory analysis of the Benin solar dataset.\n",
    "\n",
    "Notes:\n",
    "- Place your raw CSV at `data/benin.csv`. Do NOT commit CSV files (data/ is in `.gitignore`).\n",
    "- The cleaned DataFrame is exported to `data/benin_clean.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# plotting defaults\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd61ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (adjust Timestamp column name if different)\n",
    "data_path = 'data/benin.csv'\n",
    "if not os.path.exists(data_path):\n",
    "    print(f'WARNING: {data_path} not found. Drop your raw file in data/ and re-run this cell.')\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_path, parse_dates=['Timestamp'])\n",
    "except Exception:\n",
    "    # fallback: read without parsing and try to infer later\n",
    "    df = pd.read_csv(data_path)\n",
    "    if 'Timestamp' in df.columns:\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "\n",
    "print('Rows, Columns:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d60166",
   "metadata": {},
   "source": [
    "## Summary statistics & missing-value report\n",
    "Run descriptive stats on numeric columns and find columns with >5% nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264e7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "num_desc = df.describe(include=[np.number]).T\n",
    "num_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94751d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values summary\n",
    "na_counts = df.isna().sum()\n",
    "na_pct = (na_counts / len(df)) * 100\n",
    "missing_report = pd.DataFrame({'n_missing': na_counts, 'pct_missing': na_pct})\n",
    "missing_report.sort_values('pct_missing', ascending=False).head(40)\n",
    "\n",
    "# Columns with >5% nulls\n",
    "cols_gt5pct = missing_report[missing_report['pct_missing'] > 5].index.tolist()\n",
    "print('Columns with >5% nulls:', cols_gt5pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b710c0c",
   "metadata": {},
   "source": [
    "## Outlier detection & basic cleaning\n",
    "Compute Z-scores for core numeric sensors and flag extreme rows (|Z| > 3). Then impute medians for key columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key measurement columns to check - adjust names if your CSV uses different headers\n",
    "key_cols = [c for c in ['GHI','DNI','DHI','ModA','ModB','WS','WSgust'] if c in df.columns]\n",
    "key_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute z-scores (omit NaNs) and flag outliers\n",
    "z_df = pd.DataFrame(index=df.index)\n",
    "for c in key_cols:\n",
    "    try:\n",
    "        z_df[c] = stats.zscore(df[c].astype(float), nan_policy='omit')\n",
    "    except Exception:\n",
    "        z_df[c] = np.nan\n",
    "\n",
    "# any absolute z > 3\n",
    "outlier_mask = (z_df.abs() > 3).any(axis=1)\n",
    "df['outlier_flag'] = outlier_mask\n",
    "print('Outliers flagged:', df['outlier_flag'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute median for key columns (safe, robust)\n",
    "for c in key_cols:\n",
    "    if df[c].isna().any():\n",
    "        med = df[c].median()\n",
    "        df[c] = df[c].fillna(med)\n",
    "        print(f'Imputed median for {c}: {med}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bf1173",
   "metadata": {},
   "source": [
    "### Export cleaned dataframe\n",
    "Export to `data/benin_clean.csv`. This file is intentionally placed under data/ which is ignored by git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = 'data/benin_clean.csv'\n",
    "os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "df.to_csv(out_path, index=False)\n",
    "print('Wrote cleaned CSV to', out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f341336",
   "metadata": {},
   "source": [
    "## Time series analysis\n",
    "Plot GHI, DNI, DHI, Tamb vs Timestamp and inspect daily/monthly patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2570fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_cols = [c for c in ['GHI','DNI','DHI','Tamb'] if c in df.columns]\n",
    "if 'Timestamp' in df.columns:\n",
    "    df = df.sort_values('Timestamp')\n",
    "    plt.figure(figsize=(14,6))\n",
    "    for c in ts_cols:\n",
    "        plt.plot(df['Timestamp'], df[c], label=c, alpha=0.8)\n",
    "    plt.legend()\n",
    "    plt.title('Time series of irradiance and temperature')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Value')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No Timestamp column found; cannot plot time series')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f498296d",
   "metadata": {},
   "source": [
    "## Cleaning impact (if you have a Cleaning flag)\n",
    "Group by cleaning flag and compare ModA/ModB before/after. Adjust the column name if necessary (e.g., 'Cleaning', 'cleaned')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Cleaning' in df.columns or 'cleaned' in df.columns:\n",
    "    flag_col = 'Cleaning' if 'Cleaning' in df.columns else 'cleaned'\n",
    "    grp = df.groupby(flag_col)[['ModA','ModB']].mean()\n",
    "    display(grp)\n",
    "    grp.plot(kind='bar', figsize=(8,4), title='Average ModA/ModB by cleaning flag')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No cleaning flag column found; skipping cleaning-impact plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec9c0dd",
   "metadata": {},
   "source": [
    "## Correlations & relationships\n",
    "Heatmap for correlations and scatter plots to investigate relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0122e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_cols = [c for c in ['GHI','DNI','DHI','TModA','TModB','ModA','ModB','WS','WSgust','RH','Tamb'] if c in df.columns]\n",
    "if corr_cols:\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(df[corr_cols].corr(), annot=True, fmt='.2f', cmap='vlag')\n",
    "    plt.title('Correlation heatmap')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No correlation columns found from the expected list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter examples\n",
    "if 'WS' in df.columns and 'GHI' in df.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.scatterplot(x='WS', y='GHI', data=df, alpha=0.6)\n",
    "    plt.title('WS vs GHI')\n",
    "    plt.show()\n",
    "\n",
    "if 'RH' in df.columns and 'Tamb' in df.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.scatterplot(x='RH', y='Tamb', data=df, alpha=0.6)\n",
    "    plt.title('RH vs Tamb')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da46d106",
   "metadata": {},
   "source": [
    "## Wind & distribution analysis\n",
    "If you have wind direction (`WD`) and speed (`WS`) the section below attempts a simple radial histogram (wind rose approximation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set(['WD','WS']).issubset(df.columns):\n",
    "    # simple wind rose approximation: bin directions and plot mean speed by sector\n",
    "    bins = np.arange(0, 361, 30)\n",
    "    df['wd_bin'] = pd.cut(df['WD'] % 360, bins=bins, include_lowest=True)\n",
    "    rose = df.groupby('wd_bin')['WS'].mean().reset_index()\n",
    "    # polar plot\n",
    "    angles = np.deg2rad((bins[:-1] + bins[1:]) / 2)\n",
    "    values = rose['WS'].values\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111, polar=True)\n",
    "    ax.bar(angles, values, width=np.deg2rad(30), bottom=0.0, alpha=0.7)\n",
    "    ax.set_title('Wind rose (mean WS by sector)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('WD or WS columns missing; skipping wind rose')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedec506",
   "metadata": {},
   "source": [
    "## Temperature & humidity interactions\n",
    "Look at RH influence on temperature and solar radiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8842b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'RH' in df.columns and 'Tamb' in df.columns and 'GHI' in df.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.scatterplot(x='RH', y='Tamb', size='GHI', data=df, alpha=0.6, sizes=(10,200))\n",
    "    plt.title('RH vs Tamb (bubble size = GHI)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('One of RH, Tamb, or GHI is missing; skipping bubble chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0a91a8",
   "metadata": {},
   "source": [
    "## Notes & next steps\n",
    "- Consider adding `pytest` and a small test that validates the cleaned CSV schema.\n",
    "- If you want automated profiling, consider `pandas-profiling` or `ydata-profiling` (add to `requirements-dev.txt`).\n",
    "- For heavy datasets, work with chunked reads or Dask."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
